{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8176e0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6e2d3084",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.core.numeric import True_\n",
    "from sklearn import metrics\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import plot_confusion_matrix, plot_roc_curve, plot_precision_recall_curve\n",
    "from sklearn.metrics import precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "afafb3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    st.title(\"Welcome to Shopee Review\")\n",
    "    st.sidebar.title(\"This is the sidebar\")\n",
    "    st.sidebar.markdown(\"Letâ€™s start with binary classification!!\")\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7a9ffcf6",
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalHashError",
     "evalue": "module '__main__' has no attribute '__file__'\n\nWhile caching the body of `load()`, Streamlit encountered an\nobject of type `builtins.function`, which it does not know how to hash.\n\n**In this specific case, it's very likely you found a Streamlit bug so please\n[file a bug report here.]\n(https://github.com/streamlit/streamlit/issues/new/choose)**\n\nIn the meantime, you can try bypassing this error by registering a custom\nhash function via the `hash_funcs` keyword in @st.cache(). For example:\n\n```\n@st.cache(hash_funcs={builtins.function: my_hash_func})\ndef my_func(...):\n    ...\n```\n\nIf you don't know where the object of type `builtins.function` is coming\nfrom, try looking at the hash chain below for an object that you do recognize,\nthen pass that to `hash_funcs` instead:\n\n```\nObject of type builtins.function: <function load at 0x00000244001AB550>\n```\n\nPlease see the `hash_funcs` [documentation]\n(https://docs.streamlit.io/library/advanced-features/caching#the-hash_funcs-parameter)\nfor more details.\n            ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\envs\\hehe\\lib\\site-packages\\streamlit\\legacy_caching\\hashing.py\u001b[0m in \u001b[0;36mto_bytes\u001b[1;34m(self, obj, context)\u001b[0m\n\u001b[0;32m    367\u001b[0m             \u001b[1;31m# Hash the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 368\u001b[1;33m             \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mb\"%s:%s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_to_bytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    369\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\hehe\\lib\\site-packages\\streamlit\\legacy_caching\\hashing.py\u001b[0m in \u001b[0;36m_to_bytes\u001b[1;34m(self, obj, context)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 631\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_file_should_be_hashed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__code__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mco_filename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    632\u001b[0m                 \u001b[0mcontext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\hehe\\lib\\site-packages\\streamlit\\legacy_caching\\hashing.py\u001b[0m in \u001b[0;36m_file_should_be_hashed\u001b[1;34m(self, filename)\u001b[0m\n\u001b[0;32m    409\u001b[0m         return file_util.file_is_in_folder_glob(\n\u001b[1;32m--> 410\u001b[1;33m             \u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_main_script_directory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    411\u001b[0m         ) or file_util.file_in_pythonpath(filepath)\n",
      "\u001b[1;32m~\\anaconda3\\envs\\hehe\\lib\\site-packages\\streamlit\\legacy_caching\\hashing.py\u001b[0m in \u001b[0;36m_get_main_script_directory\u001b[1;34m()\u001b[0m\n\u001b[0;32m    716\u001b[0m         \u001b[1;31m# script path in ScriptRunner.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 717\u001b[1;33m         \u001b[0mmain_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m__main__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__file__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    718\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module '__main__' has no attribute '__file__'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInternalHashError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12764/201315870.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\hehe\\lib\\site-packages\\streamlit\\legacy_caching\\caching.py\u001b[0m in \u001b[0;36mwrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    572\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mshow_spinner\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    573\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspinner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 574\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mget_or_create_cached_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    575\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    576\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mget_or_create_cached_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\hehe\\lib\\site-packages\\streamlit\\legacy_caching\\caching.py\u001b[0m in \u001b[0;36mget_or_create_cached_value\u001b[1;34m()\u001b[0m\n\u001b[0;32m    497\u001b[0m                 \u001b[1;31m# If we generated the key earlier we would only hash those\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m                 \u001b[1;31m# globals by name, and miss changes in their code or value.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m                 \u001b[0mcache_key\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_hash_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhash_funcs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    500\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m             \u001b[1;31m# First, get the cache that's attached to this function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\hehe\\lib\\site-packages\\streamlit\\legacy_caching\\caching.py\u001b[0m in \u001b[0;36m_hash_func\u001b[1;34m(func, hash_funcs)\u001b[0m\n\u001b[0;32m    623\u001b[0m     \u001b[1;31m# because this step will be hashing any objects referenced in the function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m     \u001b[1;31m# body.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 625\u001b[1;33m     update_hash(\n\u001b[0m\u001b[0;32m    626\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m         \u001b[0mhasher\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfunc_hasher\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\hehe\\lib\\site-packages\\streamlit\\legacy_caching\\hashing.py\u001b[0m in \u001b[0;36mupdate_hash\u001b[1;34m(val, hasher, hash_reason, hash_source, context, hash_funcs)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[0mch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_CodeHasher\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhash_funcs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m     \u001b[0mch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhasher\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\hehe\\lib\\site-packages\\streamlit\\legacy_caching\\hashing.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, hasher, obj, context)\u001b[0m\n\u001b[0;32m    391\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhasher\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mContext\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    392\u001b[0m         \u001b[1;34m\"\"\"Update the provided hasher with the hash of an object.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 393\u001b[1;33m         \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_bytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    394\u001b[0m         \u001b[0mhasher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\hehe\\lib\\site-packages\\streamlit\\legacy_caching\\hashing.py\u001b[0m in \u001b[0;36mto_bytes\u001b[1;34m(self, obj, context)\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    381\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 382\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mInternalHashError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    383\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\hehe\\lib\\site-packages\\streamlit\\legacy_caching\\hashing.py\u001b[0m in \u001b[0;36mto_bytes\u001b[1;34m(self, obj, context)\u001b[0m\n\u001b[0;32m    366\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    367\u001b[0m             \u001b[1;31m# Hash the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 368\u001b[1;33m             \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mb\"%s:%s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_to_bytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    369\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    370\u001b[0m             \u001b[1;31m# Hmmm... It's possible that the size calculation is wrong. When we\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\hehe\\lib\\site-packages\\streamlit\\legacy_caching\\hashing.py\u001b[0m in \u001b[0;36m_to_bytes\u001b[1;34m(self, obj, context)\u001b[0m\n\u001b[0;32m    629\u001b[0m             \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhashlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"md5\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 631\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_file_should_be_hashed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__code__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mco_filename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    632\u001b[0m                 \u001b[0mcontext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    633\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__defaults__\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\hehe\\lib\\site-packages\\streamlit\\legacy_caching\\hashing.py\u001b[0m in \u001b[0;36m_file_should_be_hashed\u001b[1;34m(self, filename)\u001b[0m\n\u001b[0;32m    408\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    409\u001b[0m         return file_util.file_is_in_folder_glob(\n\u001b[1;32m--> 410\u001b[1;33m             \u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_main_script_directory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    411\u001b[0m         ) or file_util.file_in_pythonpath(filepath)\n\u001b[0;32m    412\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\hehe\\lib\\site-packages\\streamlit\\legacy_caching\\hashing.py\u001b[0m in \u001b[0;36m_get_main_script_directory\u001b[1;34m()\u001b[0m\n\u001b[0;32m    715\u001b[0m         \u001b[1;31m# This works because we set __main__.__file__ to the report\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    716\u001b[0m         \u001b[1;31m# script path in ScriptRunner.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 717\u001b[1;33m         \u001b[0mmain_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m__main__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__file__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    718\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    719\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInternalHashError\u001b[0m: module '__main__' has no attribute '__file__'\n\nWhile caching the body of `load()`, Streamlit encountered an\nobject of type `builtins.function`, which it does not know how to hash.\n\n**In this specific case, it's very likely you found a Streamlit bug so please\n[file a bug report here.]\n(https://github.com/streamlit/streamlit/issues/new/choose)**\n\nIn the meantime, you can try bypassing this error by registering a custom\nhash function via the `hash_funcs` keyword in @st.cache(). For example:\n\n```\n@st.cache(hash_funcs={builtins.function: my_hash_func})\ndef my_func(...):\n    ...\n```\n\nIf you don't know where the object of type `builtins.function` is coming\nfrom, try looking at the hash chain below for an object that you do recognize,\nthen pass that to `hash_funcs` instead:\n\n```\nObject of type builtins.function: <function load at 0x00000244001AB550>\n```\n\nPlease see the `hash_funcs` [documentation]\n(https://docs.streamlit.io/library/advanced-features/caching#the-hash_funcs-parameter)\nfor more details.\n            "
     ]
    }
   ],
   "source": [
    "@st.cache(persist= True)\n",
    "def load():\n",
    "    data= pd.read_csv(\"review_shopee_1.csv\")\n",
    "    label= LabelEncoder()\n",
    "    for i in data.columns:\n",
    "        data[i] = label.fit_transform(data[i])\n",
    "    return data\n",
    "\n",
    "df = load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff760917",
   "metadata": {},
   "outputs": [],
   "source": [
    "if st.sidebar.checkbox(\"Display data\", False):\n",
    "    st.subheader(\"Show Review Shopee dataset\")\n",
    "    st.write(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f2ab9f05",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12764/2284860010.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m     \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "@st.cache(persist=True)\n",
    "def split(df):\n",
    "    y = df.type\n",
    "    x = df.drop(columns=[\"type\"])\n",
    "    x_train, x_test, y_train, y_test =     train_test_split(x,y,test_size=0.3, random_state=0)\n",
    "    return x_train, x_test, y_train, y_test\n",
    "x_train, x_test, y_train, y_test = split(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "177823b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(metrics_list):\n",
    "    if \"Confusion Matrix\" in metrics_list:\n",
    "        st.subheader(\"Confusion Matrix\")\n",
    "        plot_confusion_matrix(model, x_test, y_test, display_labels=   class_names)\n",
    "        st.pyplot()\n",
    "    if \"ROC Curve\" in metrics_list:\n",
    "        st.subheader(\"ROC Curve\")\n",
    "        plot_roc_curve(model, x_test, y_test)\n",
    "        st.pyplot()\n",
    "    if \"Precision-Recall Curve\" in metrics_list:\n",
    "        st.subheader(\"Precision-Recall Curve\") \n",
    "        plot_precision_recall_curve(model, x_test, y_test)\n",
    "        st.pyplot()\n",
    "class_names = [\"good\", \"bad\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d01034b",
   "metadata": {},
   "outputs": [],
   "source": [
    "st.sidebar.subheader(\"Choose classifier\")\n",
    "classifier = st.sidebar.selectbox(\"Classifier\", (\"Support Vector Machine (SVM)\", \"Logistic Regression\", \"Random Forest\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8742a800",
   "metadata": {},
   "outputs": [],
   "source": [
    "if classifier == \"Support Vector Machine (SVM)\":\n",
    "    st.sidebar.subheader(\"Hyperparameters\")\n",
    "    C = st.sidebar.number_input(\"C (Regularization parameter)\", 0.01, 10.0, step=0.01, key=\"C\")\n",
    "    kernel = st.sidebar.radio(\"Kernel\", (\"rbf\", \"linear\"), key=\"kernel\") \n",
    "    gamma = st.sidebar.radio(\"Gamma (Kernal coefficient\", (\"scale\", \"auto\"), key=\"gamma\")\n",
    "metrics = st.sidebar.multiselect(\"What metrics to plot?\", (\"Confusion Matrix\", \"ROC Curve\", \"Precision-Recall Curve\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "945d3b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "if st.sidebar.button(\"Classify\", key=\"classify\"):\n",
    "    st.subheader(\"Support Vector Machine (SVM) results\")\n",
    "    model = SVC(C=C, kernel=kernel, gamma=gamma)\n",
    "    model.fit(x_train, y_train)\n",
    "    accuracy = model.score(x_test, y_test)\n",
    "    y_pred = model.predict(x_test)\n",
    "    st.write(\"Accuracy: \", accuracy.round(2))\n",
    "    st.write(\"Precision: \", precision_score(y_test, y_pred, labels=class_names).round(2))\n",
    "    st.write(\"Recall: \", recall_score(y_test, y_pred, labels=class_names).round(2)) \n",
    "    plot_metrics(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09b78411",
   "metadata": {},
   "outputs": [],
   "source": [
    "if classifier == \"Logistic Regression\":\n",
    "    st.sidebar.subheader(\"Hyperparameters\")\n",
    "    C = st.sidebar.number_input(\"C (Regularization parameter)\", 0.01, 10.0, step=0.01, key=\"C_LR\")\n",
    "    max_iter = st.sidebar.slider(\"Maximum iterations\", 100, 500, key=\"max_iter\")\n",
    "    metrics = st.sidebar.multiselect(\"What metrics to plot?\", (\"Confusion Matrix\", \"ROC Curve\", \"Precision-Recall Curve\"))\n",
    "if st.sidebar.button(\"Classify\", key=\"classify\"):\n",
    "        st.subheader(\"Logistic Regression Results\")\n",
    "        model = LogisticRegression(C=C, max_iter=max_iter)\n",
    "        model.fit(x_train, y_train)\n",
    "        accuracy = model.score(x_test, y_test)\n",
    "        y_pred = model.predict(x_test)\n",
    "        \n",
    "        st.write(\"Accuracy: \", accuracy.round(2))\n",
    "        st.write(\"Precision: \", precision_score(y_test, y_pred, labels=class_names).round(2))\n",
    "        st.write(\"Recall: \", recall_score(y_test, y_pred, labels=class_names).round(2))\n",
    "        plot_metrics(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5ca60885",
   "metadata": {},
   "outputs": [],
   "source": [
    "if classifier == \"Random Forest\":\n",
    "    st.sidebar.subheader(\"Hyperparameters\")\n",
    "    n_estimators= st.sidebar.number_input(\"The number of trees in the forest\", 100, 5000, step=10, key=\"n_estimators\")\n",
    "    max_depth = st.sidebar.number_input(\"The maximum depth of tree\", 1, 20, step =1, key=\"max_depth\")\n",
    "    bootstrap = st.sidebar.radio(\"Bootstrap samples when building trees\", (\"True\", \"False\"), key=\"bootstrap\")\n",
    "    \n",
    "    metrics = st.sidebar.multiselect(\"What metrics to plot?\", (\"Confusion Matrix\", \"ROC Curve\", \"Precision-Recall Curve\"))\n",
    "if st.sidebar.button(\"Classify\", key=\"classify\"):\n",
    "        st.subheader(\"Random Forest Results\")\n",
    "        model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, bootstrap= bootstrap, n_jobs=-1 )\n",
    "        model.fit(x_train, y_train)\n",
    "        accuracy = model.score(x_test, y_test)\n",
    "        y_pred = model.predict(x_test)\n",
    "        st.write(\"Accuracy: \", accuracy.round(2))\n",
    "        st.write(\"Precision: \", precision_score(y_test, y_pred, labels=class_names).round(2))\n",
    "        st.write(\"Recall: \", recall_score(y_test, y_pred, labels=class_names).round(2))\n",
    "        plot_metrics(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0672d23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
